{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHyyixbeAGKdIexAhJ3TxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandresvifpb/assert_iaiot/blob/main/project_softex_ia_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7xOZDRpk6EJS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carregar os dados\n",
        "url = 'https://raw.githubusercontent.com/alexandresvifpb/assert_iaiot/main/letter-recognition.data'\n",
        "letter_recognition = pd.read_csv(url, header=None, names=['lettr', 'x-box', 'y-box', 'width', 'high', 'onpix', 'x-bar', 'y-bar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'x-ege', 'xegvy', 'y-ege', 'yegvx'])\n",
        "# print(letter_recognition)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "\n",
        "# 2.1. Verificar e remover valores nulos\n",
        "letter_recognition = letter_recognition.dropna()\n",
        "# print(\"numero de linhas sem valores nulos: \",len(letter_recognition))\n",
        "\n",
        "# 2.2. Converter labels para números\n",
        "label_encoder = LabelEncoder()\n",
        "letter_recognition['lettr'] = label_encoder.fit_transform(letter_recognition['lettr'])\n",
        "\n",
        "# 2.3. Verificar se existe correspondência entre features\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlation_matrix = letter_recognition.corr()\n",
        "\n",
        "# Criar um mapa de calor\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Matriz de Correlação Letter Recognition\")\n",
        "plt.show()\n",
        "\n",
        "# 2.4. Normalizar as features na escala 0..1\n",
        "scaler = MinMaxScaler()\n",
        "letter_recognition_scaled = pd.DataFrame(scaler.fit_transform(letter_recognition.drop(columns=['lettr'])), columns=letter_recognition.columns[1:])\n",
        "\n",
        "# Concatenar os labels (lettr) com as features normalizadas\n",
        "letter_recognition_processed = pd.concat([letter_recognition['lettr'], letter_recognition_scaled], axis=1)\n",
        "# print(\"\\nDataset após pré-processamento:\\n\", letter_recognition_processed.head())"
      ],
      "metadata": {
        "id": "P9fowryb6aWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.1 Gráfico de barras por classes\n",
        "# Contar a quantidade de instâncias por classe\n",
        "class_counts = letter_recognition['lettr'].value_counts()\n",
        "\n",
        "# Criar um gráfico de barras\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette='viridis')\n",
        "plt.title('Quantidade de Instâncias por Classe')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Quantidade')\n",
        "plt.show()\n",
        "\n",
        "# 3.2. Gráfico de dispersão com linha de regressão\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.regplot(x='x-box', y='lettr', data=letter_recognition, scatter_kws={'s': 20, 'alpha': 0.5}, line_kws={'color': 'red'})\n",
        "plt.title('Gráfico de Dispersão com Linha de Regressão')\n",
        "plt.xlabel('x-box')\n",
        "plt.ylabel('lettr')\n",
        "plt.show()\n",
        "\n",
        "# 3.3. Gráfico de distribuição (histograma)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(letter_recognition['x-box'], bins=30, color='skyblue', kde=True)\n",
        "plt.title('Histograma da Feature x-box')\n",
        "plt.xlabel('x-box')\n",
        "plt.ylabel('Frequência')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CwbLpIdm6ga-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos\n",
        "# Modelo 1: Árvore de Decisão com critério 'gini' e sem limite de profundidade\n",
        "dtc_model1 = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "dtc_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo 2: Árvore de Decisão com critério 'entropy' e profundidade máxima de 5\n",
        "dtc_model2 = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
        "dtc_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 10\n",
        "accuracies_dtc_model1 = cross_val_score(dtc_model1, X, y, cv=num_executions)\n",
        "accuracies_dtc_model2 = cross_val_score(dtc_model2, X, y, cv=num_executions)\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_dtc_model1 = accuracies_dtc_model1.mean()\n",
        "mean_accuracy_dtc_model2 = accuracies_dtc_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para Modelo 1: {mean_accuracy_dtc_model1:.3%}')\n",
        "print(f'Média de Acurácia para Modelo 2: {mean_accuracy_dtc_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7QutbzY6l-U",
        "outputId": "a8b7fc9a-54f5-4014-a546-64146e786619"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para Modelo 1: 88.380%\n",
            "Média de Acurácia para Modelo 2: 50.365%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos KNN\n",
        "# Modelo KNN 1: K=3, Métrica Euclidiana\n",
        "knn_model1 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "knn_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo KNN 2: K=5, Métrica Manhattan\n",
        "knn_model2 = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n",
        "knn_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 10\n",
        "accuracies_knn_model1 = cross_val_score(knn_model1, X, y, cv=num_executions)\n",
        "accuracies_knn_model2 = cross_val_score(knn_model2, X, y, cv=num_executions)\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_knn_model1 = accuracies_knn_model1.mean()\n",
        "mean_accuracy_knn_model2 = accuracies_knn_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para KNN Modelo 1: {mean_accuracy_knn_model1:.3%}')\n",
        "print(f'Média de Acurácia para KNN Modelo 2: {mean_accuracy_knn_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSrIM89265sv",
        "outputId": "f3970439-5808-47d9-c19b-ba1d5c9c4d3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para KNN Modelo 1: 95.610%\n",
            "Média de Acurácia para KNN Modelo 2: 95.520%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos MLP\n",
        "# Modelo MLP 1: Topologia (100, 50), 1000 ciclos, função de ativação adaptive\n",
        "mlp_model1 = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=1000, learning_rate='adaptive', random_state=42)\n",
        "mlp_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo MLP 2: Topologia (150, 50), 900 ciclos, função de ativação Tangente Hiperbólica\n",
        "mlp_model2 = MLPClassifier(hidden_layer_sizes=(150, 50), max_iter=900, activation='tanh', random_state=42)\n",
        "mlp_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 2\n",
        "accuracies_mlp_model1 = cross_val_score(mlp_model1, X, y, cv=num_executions)\n",
        "accuracies_mlp_model2 = cross_val_score(mlp_model2, X, y, cv=num_executions)\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_mlp_model1 = accuracies_mlp_model1.mean()\n",
        "mean_accuracy_mlp_model2 = accuracies_mlp_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para MLP Modelo 1: {mean_accuracy_mlp_model1:.3%}')\n",
        "print(f'Média de Acurácia para MLP Modelo 2: {mean_accuracy_mlp_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTpP1v2T68yL",
        "outputId": "74dc880a-479f-4cb6-9bdd-a911dacb304c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para MLP Modelo 1: 91.500%\n",
            "Média de Acurácia para MLP Modelo 2: 71.625%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:693: UserWarning: Training interrupted by user.\n",
            "  warnings.warn(\"Training interrupted by user.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos SVM\n",
        "# Modelo SVM 1: Kernel RBF, C=1, gamma='scale'\n",
        "svm_model1 = SVC(kernel='rbf', C=1, gamma='scale')\n",
        "svm_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo SVM 2: Kernel Linear, C=0.5, gamma='auto'\n",
        "svm_model2 = SVC(kernel='linear', C=0.75, gamma='auto')\n",
        "svm_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 2\n",
        "accuracies_svm_model1 = cross_val_score(svm_model1, X, y, cv=num_executions)\n",
        "accuracies_svm_model2 = cross_val_score(svm_model2, X, y, cv=num_executions)\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_svm_model1 = accuracies_svm_model1.mean()\n",
        "mean_accuracy_svm_model2 = accuracies_svm_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para SVM Modelo 1: {mean_accuracy_svm_model1:.3%}')\n",
        "print(f'Média de Acurácia para SVM Modelo 2: {mean_accuracy_svm_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yovIKpU06_Dl",
        "outputId": "4ed1ed4c-e810-4ae9-8151-c1440a8c3480"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para SVM Modelo 1: 90.750%\n",
            "Média de Acurácia para SVM Modelo 2: 79.775%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos\n",
        "# Modelo 1: Árvore de Decisão com critério 'gini' e sem limite de profundidade\n",
        "# dtc_model1 = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "# dtc_model1.fit(X_train, y_train)\n",
        "# Modelo Random Forest 1\n",
        "rf_model1 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo 2: Árvore de Decisão com critério 'entropy' e profundidade máxima de 5\n",
        "# dtc_model2 = DecisionTreeClassifier(criterion='entropy', max_depth=5, random_state=42)\n",
        "# dtc_model2.fit(X_train, y_train)\n",
        "# Modelo Random Forest 2\n",
        "rf_model2 = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
        "rf_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 2\n",
        "accuracies_rf_model1 = cross_val_score(rf_model1, X, y, cv=num_executions)\n",
        "accuracies_rf_model2 = cross_val_score(rf_model2, X, y, cv=num_executions)\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_rf_model1 = accuracies_rf_model1.mean()\n",
        "mean_accuracy_rf_model2 = accuracies_rf_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para Modelo 1: {mean_accuracy_rf_model1:.3%}')\n",
        "print(f'Média de Acurácia para Modelo 2: {mean_accuracy_rf_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqQs5WD_7DYf",
        "outputId": "37cf282d-75fb-4f75-a42e-04034cca816c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para Modelo 1: 96.595%\n",
            "Média de Acurácia para Modelo 2: 87.020%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "\n",
        "# 4.1 Separar os dados de treinamento e teste (80% e 20%)\n",
        "X = letter_recognition_processed.drop(columns=['lettr'])\n",
        "y = letter_recognition_processed['lettr']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4.2 Treinar os modelos XGBoost\n",
        "# Modelo XGBoost 1\n",
        "xgb_model1 = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y)), random_state=42)\n",
        "xgb_model1.fit(X_train, y_train)\n",
        "\n",
        "# Modelo XGBoost 2\n",
        "xgb_model2 = xgb.XGBClassifier(objective='multi:softmax', num_class=len(np.unique(y)), max_depth=10, learning_rate=0.05, random_state=42)\n",
        "xgb_model2.fit(X_train, y_train)\n",
        "\n",
        "# 4.3 Executar 10 vezes o Train-Test-Split\n",
        "num_executions = 2\n",
        "accuracies_xgb_model1 = cross_val_score(xgb_model1, X, y, cv=num_executions, scoring='accuracy')\n",
        "accuracies_xgb_model2 = cross_val_score(xgb_model2, X, y, cv=num_executions, scoring='accuracy')\n",
        "\n",
        "# 4.4 Apresentar a média das 10 execuções dos resultados de acurácia de todos os modelos\n",
        "mean_accuracy_xgb_model1 = accuracies_xgb_model1.mean()\n",
        "mean_accuracy_xgb_model2 = accuracies_xgb_model2.mean()\n",
        "\n",
        "print(f'Média de Acurácia para XGBoost Modelo 1: {mean_accuracy_xgb_model1:.3%}')\n",
        "print(f'Média de Acurácia para XGBoost Modelo 2: {mean_accuracy_xgb_model2:.3%}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjZVNgCd7HEg",
        "outputId": "7894d2e0-8563-4117-fad0-c8e221a2d26e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média de Acurácia para XGBoost Modelo 1: 94.590%\n",
            "Média de Acurácia para XGBoost Modelo 2: 92.845%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Criar um DataFrame para armazenar os resultados\n",
        "results = pd.DataFrame(columns=['Modelo', 'Média de Acurácia'])\n",
        "\n",
        "# Adicionar resultados dos modelos à tabela\n",
        "results = pd.concat([\n",
        "    results,\n",
        "    pd.DataFrame({'Modelo': ['Decision Tree Modelo 1'], 'Média de Acurácia': [mean_accuracy_dtc_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['Decision Tree Modelo 2'], 'Média de Acurácia': [mean_accuracy_dtc_model2]}),\n",
        "    pd.DataFrame({'Modelo': ['KNN Modelo 1'], 'Média de Acurácia': [mean_accuracy_knn_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['KNN Modelo 2'], 'Média de Acurácia': [mean_accuracy_knn_model2]}),\n",
        "    pd.DataFrame({'Modelo': ['MLP Modelo 1'], 'Média de Acurácia': [mean_accuracy_mlp_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['MLP Modelo 2'], 'Média de Acurácia': [mean_accuracy_mlp_model2]}),\n",
        "    pd.DataFrame({'Modelo': ['SVM Modelo 1'], 'Média de Acurácia': [mean_accuracy_svm_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['SVM Modelo 2'], 'Média de Acurácia': [mean_accuracy_svm_model2]}),\n",
        "    pd.DataFrame({'Modelo': ['Random Forest Modelo 1'], 'Média de Acurácia': [mean_accuracy_rf_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['Random Forest Modelo 2'], 'Média de Acurácia': [mean_accuracy_rf_model2]}),\n",
        "    pd.DataFrame({'Modelo': ['XGBoost Modelo 1'], 'Média de Acurácia': [mean_accuracy_xgb_model1]}),\n",
        "    pd.DataFrame({'Modelo': ['XGBoost Modelo 2'], 'Média de Acurácia': [mean_accuracy_xgb_model2]})\n",
        "], ignore_index=True)\n",
        "\n",
        "# Apresentar a tabela\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gbe2NG3E7IY9",
        "outputId": "2e4c98a6-e0c4-4899-9c90-897c65c470b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Modelo  Média de Acurácia\n",
            "0   Decision Tree Modelo 1            0.88380\n",
            "1   Decision Tree Modelo 2            0.50365\n",
            "2             KNN Modelo 1            0.95610\n",
            "3             KNN Modelo 2            0.95520\n",
            "4             MLP Modelo 1            0.91500\n",
            "5             MLP Modelo 2            0.71625\n",
            "6             SVM Modelo 1            0.90750\n",
            "7             SVM Modelo 2            0.79775\n",
            "8   Random Forest Modelo 1            0.96595\n",
            "9   Random Forest Modelo 2            0.87020\n",
            "10        XGBoost Modelo 1            0.94590\n",
            "11        XGBoost Modelo 2            0.92845\n"
          ]
        }
      ]
    }
  ]
}